{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "390fd3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faa2b0e",
   "metadata": {},
   "source": [
    "## 데이타 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4fb6594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#conversation_lines = os.path.join('~/aiffel/transformer_chatbot/data/ChatbotData.csv')\n",
    "conversation_lines = os.getenv('HOME')+'/aiffel/transformer_chatbot/data/ChatbotData.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a2176a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "\n",
    "  # 소문자화 & 공백 제거 (한국어는 대소문자 의미 없음, 하지만 영어 혼합 대비)\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)  # 구두점 앞뒤로 공백추가\n",
    " \n",
    "  # 허용된 문자 외 제거 (한글, 영어, 숫자, 구두점)\n",
    "  sentence = re.sub(r\"[^가-힣a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
    "  \n",
    "  # 다중 공백 정리\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)        # 여러개의 공백을 하나로\n",
    "  \n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4a7e9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d3525875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4776b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "\n",
    "  inputs, outputs = [], []\n",
    "  with open(conversation_lines, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    # 첫 줄은 헤더니까 건너뜁니다\n",
    "    for line in lines[1:]:\n",
    "        parts = line.strip().split(',')\n",
    "        if len(parts) >= 2:\n",
    "            question, answer = parts[0], parts[1]\n",
    "            inputs.append(preprocess_sentence(question))\n",
    "            outputs.append(preprocess_sentence(answer))\n",
    "\n",
    "    if len(inputs) >= MAX_SAMPLES:\n",
    "        return inputs, outputs\n",
    "  return inputs, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "38dd1553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "import csv\n",
    "\n",
    "def load_conversations_csv():\n",
    "\n",
    "  inputs, outputs = [], []\n",
    "  with open(conversation_lines, 'r') as file:\n",
    "        \n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # 첫 줄은 헤더이므로 건너뜀\n",
    "    \n",
    "    for row in reader:\n",
    "        if len(row) >= 2:\n",
    "            question, answer = row[0], row[1]\n",
    "            inputs.append(preprocess_sentence(question))\n",
    "            outputs.append(preprocess_sentence(answer))\n",
    "\n",
    "        if len(inputs) >= MAX_SAMPLES:\n",
    "            break\n",
    "        \n",
    "  \n",
    "  return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa724744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "55911a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 . \n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b790b467",
   "metadata": {},
   "source": [
    "**Subword Tokenizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28272ead",
   "metadata": {},
   "source": [
    "1) TensorFlow Datasets SubwordTextEncoder 를 토크나이저로 사용한다.  \n",
    "    단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고,  각 토큰을 고유한 정수로 인코딩 한다.\n",
    "\n",
    "2) 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가한다.\n",
    "\n",
    "3) 최대 길이 MAX_LENGTH 인 40을 넘는 문장들은 필터링한다.\n",
    "\n",
    "4) MAX_LENGTH보다 길이가 짧은 문장들은 40에 맞도록 패딩 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1bbe4c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "# 인자 : corpus = 문자열 리스트, target_vocab_size = 원하는 어휘 수\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1f456198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8142]\n",
      "END_TOKEN의 번호 : [8143]\n",
      "8144\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1a8be62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6c09cd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8144\n",
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c475e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]  # 디코더 입력 (교사 강요용),  END_TOKEN 제거\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]      # 디코더 출력 (정답), START_TOKEN 제거\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()                       # 메모리에 캐싱, 에포크가 반복될때 디스크 읽기/파싱 비용을 줄임\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)          # 무작위로 섞지 않으면, 학습이 데이터 순서에 의존하게 되어 과적합 위험이 높아짐\n",
    "dataset = dataset.batch(BATCH_SIZE)             # 배치로 묶어서 모델에 한번에 전달\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE) # GPU가 학습하는 동안 CPU가 다음 배치를 미리 준비\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a2ba4a",
   "metadata": {},
   "source": [
    "## 공통 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe01b7d",
   "metadata": {},
   "source": [
    "**포지셔널 인코딩 레이어**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "321ea202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "# d_model : 임베딩 벡터의 차원,  각 단어 벡터의 차원 (예: 512)\n",
    "# position: 입력 문장에서의 임베딩 벡터의 위치, 시퀀스의 최대 길이 \n",
    "# i       : 임베딩 벡터 내의 차원의 인덱스를 의미\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):                                      # max_position length 만큼                          \n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)           # 미리 전체 포지션 인코딩을 계산해서 저장\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32)) # 공식에 따라 포지션과 차원 인덱스에 따라 각도를 계산 \n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "    # (position, 1) 열 벡터, (1, i(d_model)) 행 벡터\n",
    "    # 모든 위치와 모든 차원에ㅔ 대해 고유한  angle 값 계산\n",
    "    # angle_rads : (position, d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용 (모든 position, d_model은 0부터 시작해서 2깐씩)\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용 (1부터 시작해서 2깐씩)\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "    # sines : (position, d_model/2)\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    # pos_encoding : (2, position, d_model/2)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    # pos_encoding : (position, d_model/2, 2)\n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "    # pos_encoding : (position, d_model)\n",
    "    # → sin/cos을 번갈아 interleave해서 (position, d_model)로 만드는 과정\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    # 배치 차원 추가 \n",
    "    # pos_encoding : (1, position, d_model)  → 여기서 1은 broadcast돼서 batch_size만큼 자동으로 복제됨\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # inputs : (batch_size, seq_len, d_model)\n",
    "    # self.pos_encoding : (1, max_position, d_model)\n",
    "    # inputs의 seq_len <= max_position\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]  # 입력 텐서에 위치 인코딩을 더해줌\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d82ab48",
   "metadata": {},
   "source": [
    "**어텐션**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d65e7",
   "metadata": {},
   "source": [
    "![Attention](./scaled_dot_prodect_attention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "abef2b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)  # 행렬 곱셈(matrix multiplication), key를 transpose함\n",
    "  # Q: (batch_size, num_heads, seq_len_q, depth)\n",
    "  # K: (batch_size, num_heads, seq_len_k, depth)\n",
    "  # transpose : 마지막 2개 차원에 바뀜 \n",
    "  # K^T : (batch_size, num_heads, depth, seq_len_k)\n",
    "  # QK^T → shape: (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  # Q,K이 차원이 depth이고, depth가 커질수록 내적값도 커지므로, depth를 사용해서 scale을 줄여준다. \n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)       # key 마지막 차원의 크기를 float32로 변환 (부동소수점자료형)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)             # 차원수로 scaling하는 작업\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  # 마스크된 곳에는 아주 큰 마이너스 값으로 변경하여, 사용되지 않게.\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "    \n",
    "  \n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  # (seq_len_q, seq_len_k) @ (seq_len_k, depth) → (seq_len_q, depth)\n",
    "  # attention_logits  :  (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "  # V                 :  (batch_size, num_heads, seq_len_k, depth)\n",
    "  # output            :  (batch_size, num_heads, seq_len_q, depth)\n",
    "  return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6458ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    # d_model -> num_heads * depth \n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth)) # -1: 자동으로 그 크기를 맞춰라 (seq_len)\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])                  # (batch_size, num_heads, seq_len, depth)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    \n",
    "    # inputs.shape = [batch_size, seq_len, embedding_dim]\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    # (batch_size, seq_len, embedding_dim)\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    # (batch_size, num_heads, seq_len, projection_dim(depth))\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "    # shape : (batch_size, num_heads, seq_len_q, projection_dim)\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "    # concat을 하려고 shape를 바꿈 : (batch_size, seq_len_q, num_heads, projection_dim(depth))\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다 (num_heads * depth -> d_model)\n",
    "    # (batch_size, seq_len, embedding_dim)\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e21e7aa",
   "metadata": {},
   "source": [
    "**패딩 마스크**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "997c7a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델이 의미 없는 패딩 토큰에 주의를 빼앗기지 않도록 하기 위해 **마스킹(masking)**을 한다.\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)   # [7, 6, 0, 0, 0] → [False, False, True, True, True]\n",
    "                                                    # Boolen 값을 float32로 변경 → [0.0, 0.0, 1.0, 1.0, 1.0]\n",
    "  # (batch_size, 1, 1, sequence length_k)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]         # 차원을 확장해서, 어덴션 스코어와 잘 계산되게 맞추어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "242b4b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a9c1f4",
   "metadata": {},
   "source": [
    "**룩 어헤드 마스킹(Look-ahead masking, 다음 단어 가리기)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2b7869f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  # (batch_size, seq_len, dim)\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  \n",
    "  # tf.ones((seq_len, seq_len)) : (seq_len, seq_len)인 모든 원소가 1인 텐서\n",
    "    #  [[1, 1, 1],\n",
    "    #   [1, 1, 1],\n",
    "    #   [1, 1, 1]]\n",
    "  # tf.linalg.band_part ( input, num_lower, num_upper) : 행렬의 밴드부분만 남기고 나머지는 0으로 \n",
    "  # 하삼각 행렬(lower triangular matrix)을 생성\n",
    "    #  [[1, 0, 0],\n",
    "    #   [1, 1, 0],\n",
    "    #   [1, 1, 1]]\n",
    "  # mask = 1 - 하삼각 행렬  (자신보다 뒤에 있는 토큰에 1을 설정하는 마스크 )\n",
    "    #  [[0, 1, 1],\n",
    "    #   [0, 0, 1],\n",
    "    #   [0, 0, 0]]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    " \n",
    "    \n",
    "  padding_mask = create_padding_mask(x)\n",
    "  # (batch_size, 1, 1, sequence length_k)\n",
    "\n",
    "  return tf.maximum(look_ahead_mask, padding_mask) # 내자신 이후도 보지 말고, 패딩도 보지 말라\n",
    "  # tf.maximum (a, b) : a, b는 같은 shape이거나, 브로드캐스트가 가능한 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "33517159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c0ccd687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e6cb3",
   "metadata": {},
   "source": [
    "## 인코더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02824f66",
   "metadata": {},
   "source": [
    "**인코더층**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c4f3055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "  # units : FFN의 내부 유닛 수\n",
    "  # d_model : 임베딩 차원\n",
    "  # num_heads : 멀티헤드 어센션의 헤드 개수\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    " # padding_mask.shape = (batch_size, 1, 1, seq_len_k)\n",
    " # attention_logits.shape = (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa29207",
   "metadata": {},
   "source": [
    "**인코더**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "88bf836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "  \n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  # embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  embeddings = PositionalEncoding(MAX_LENGTH, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e38993",
   "metadata": {},
   "source": [
    "## 디코더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b3211",
   "metadata": {},
   "source": [
    "**디코더층**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "95652150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "  # units : FFN의 내부 유닛 수\n",
    "  # d_model : 임베딩 차원\n",
    "  # num_heads : 멀티헤드 어센션의 헤드 개수\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    \n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  # look_ahead_mask.shape = (batch_size, 1, seq_len_q, seq_len_k)\n",
    "  # batch_size는 Keras Input에서 None으로 자동 처리\n",
    "  # 1 → num_heads 차원에 broadcasting 가능\n",
    "  # 모든 헤드에 동일한 마스크를 적용하면서도 시퀀스 길이에 따라 다르게 작동\n",
    "  # shape=(1, None, None)은 멀티헤드 어텐션에 자연스럽게 마스크를 덧붙일 수 있게 하기 위한 브로드캐스트 설계\n",
    "\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  # padding_mask.shape = (batch_size, 1, 1, seq_len_k)\n",
    "  # 1 → num_heads 차원에 broadcasting 가능\n",
    "  # 1 → seq_len_q에 대해 모든 쿼리에 동일한 마스크 적용\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5b3e2",
   "metadata": {},
   "source": [
    "**디코더**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "95286e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  # shape: (batch_size, seq_len, d_model)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  # 스케일을 키운다 -> 벡터의 값을 약간 더 강하게 만들기 위한 정규화 효과 \n",
    "  # 1) 초기 어덴션 스코어가 너무 작아지지 않도록 : 임베딩 값이 작으면 → QKᵀ의 값도 작아짐 → Softmax가 평평해지고, 학습이 느려짐\n",
    "  # 2) 어텐션 연산에서 Q, K, V의 스케일과 맞춰주기 위함 : 어텐션에서는 QKᵀ / √d_k로 나누니까, 임베딩은 * √d_model로 곱해 균형을 맞춤\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  # pos_embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  pos_embeddings = PositionalEncoding(MAX_LENGTH, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(pos_embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c314f7fe",
   "metadata": {},
   "source": [
    "## 모델 정의 및 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "23404527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1648c791",
   "metadata": {},
   "source": [
    "**손실함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "207f8d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이블인 시퀀스에 패딩이 되어 있으므로, loss를 계산할 때 패딩 마스크를 적용해야한다\n",
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1)) \n",
    "  # y_true : (batch_size, seq_len)\n",
    "  # -1 : 남은 차원은 알아서 계산\n",
    "  # seq : MAX_LENGTH - 1인 이유는 → 디코더의 정답 시퀀스는 보통 <start> 토큰 제거한 상태\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "    # from_logits=True: y_pred가 softmax 되기 전 값 (logits : softmax를 거치기 직전값)이기 때문\n",
    "    # → 손실 함수 내부에서 softmax를 자동으로 처리\n",
    "    # reduction='none': 손실을 일괄 평균하지 않고, 토큰마다 개별 손실 계산\n",
    "    # → 나중에 마스크를 씌워서 패딩 위치 손실은 제거할 수 있게 함\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "    # y_true == 0인 위치는 패딩이므로 손실에서 제외. 그래서 0인 위치는 0, 나머지는 1인 마스크 생성\n",
    "\n",
    "  return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37bfcf3",
   "metadata": {},
   "source": [
    "**Custom Learning rate Scheduling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c71f854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기엔 학습률을 점점 올리고, 그 후엔 학습률을 점점 낮추는 방식\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps                    # warmup_steps: 학습률을 올리는 단계 수\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "36cabb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyBElEQVR4nO3deZxcVZ3//9en9+4k3Uk6nZA9gYQlIAg0GVBUBJXgFpcwJsPMoKJ8HWHcZr4OjMv4ZYbvT9SvfNVBEYUBfaABUb9EjUaGRRGB0MiaQKBJAknIvnRn6+qu7s/vj3uqU2mququr6/ZW7+fjUY++de65556qdO6nz3LPNXdHRESk0EqGugIiIjI6KcCIiEgsFGBERCQWCjAiIhILBRgREYlF2VBXYChNmjTJ58yZM9TVEBEZUR5//PFd7t7QV76iDjBz5syhqalpqKshIjKimNnLueRTF5mIiMRCAUZERGKhACMiIrFQgBERkVgowIiISCxiDTBmtsjM1plZs5ldlWF/pZndEfY/amZz0vZdHdLXmdmFaem3mNkOM3s2yzn/yczczCbF8qFERCQnsQUYMysFbgAuAhYAy8xsQY9slwF73X0ecD1wXTh2AbAUOBlYBHw3lAdwa0jLdM6ZwDuAVwr6YUREpN/ibMEsBJrdfb27twPLgcU98iwGbgvbdwEXmJmF9OXunnD3DUBzKA93/yOwJ8s5rwc+DwzJMwi2t7bx+zXbhuLUIiLDTpwBZjqwKe395pCWMY+7J4EWoD7HY49iZouBLe7+VB/5LjezJjNr2rlzZy6fI2d/+8NHufzHj5NIdha0XBGRkWhUDPKbWQ3wr8CX+8rr7je5e6O7NzY09LnSQb9s3nsYgNbDyYKWKyIyEsUZYLYAM9PezwhpGfOYWRlQB+zO8dh0xwFzgafMbGPI/xczO2YA9e+36opomKjlcMdgnlZEZFiKM8A8Bsw3s7lmVkE0aL+iR54VwKVhewlwn0fPcF4BLA2zzOYC84HV2U7k7s+4+2R3n+Puc4i61M5w90EdEKkuTwWY9sE8rYjIsBRbgAljKlcCq4DngDvdfY2ZXWNm7w3ZbgbqzawZ+BxwVTh2DXAnsBb4HXCFu3cCmNlPgYeBE8xss5ldFtdn6K9UC2bfIbVgRERiXU3Z3VcCK3ukfTltuw24OMux1wLXZkhflsN55/S3roWQasEowIiIjJJB/uGiO8BoDEZERAGmkCrKoq+z5ZDGYEREFGAKqL2zC1ALRkQEFGAKKpEMAUZjMCIiCjCFlOiI7uBXC0ZERAGmoFJdZBqDERFRgCmoRIfGYEREUhRgCkhjMCIiRyjAFFBqFeXWtg46u4bkiQEiIsOGAkwBJZJdVJaV4A6t6iYTkSKnAFMg7k57soupdVUA7NFAv4gUOQWYAkmNv0wbXw3Arv2JoayOiMiQU4ApkJ4BZvdBtWBEpLgpwBRIaoB/eqoFc0AtGBEpbgowBdIeWjDH1FVhBrsOqAUjIsVNAaZAUl1kNRWlTKypUAtGRIqeAkyBpO7irywrpX5sBbsVYESkyCnAFEhqDKayvIRJYyvZrS4yESlyCjAFkuoiqywtoX5spbrIRKToxRpgzGyRma0zs2YzuyrD/kozuyPsf9TM5qTtuzqkrzOzC9PSbzGzHWb2bI+yvm5mz5vZ02b2SzMbH+dn66k7wJSXMGlshVowIlL0YgswZlYK3ABcBCwAlpnZgh7ZLgP2uvs84HrgunDsAmApcDKwCPhuKA/g1pDW0z3AKe5+KvACcHVBP1AfUs+CqSwrZdLYSvYnkrSFNBGRYhRnC2Yh0Ozu6929HVgOLO6RZzFwW9i+C7jAzCykL3f3hLtvAJpDebj7H4E9PU/m7r9392R4+wgwo9AfqDfdLZiyEurHVAC62VJEilucAWY6sCnt/eaQljFPCA4tQH2Ox/bmo8BvM+0ws8vNrMnMmnbu3NmPInvXnjwyi6xhXCUAO7VcjIgUsVE3yG9mXwCSwO2Z9rv7Te7e6O6NDQ0NBTtv+hjMlNpowcttLW0FK19EZKSJM8BsAWamvZ8R0jLmMbMyoA7YneOxr2FmHwbeDVzi7oP6QJbuacplJd0rKm9rOTyYVRARGVbiDDCPAfPNbK6ZVRAN2q/okWcFcGnYXgLcFwLDCmBpmGU2F5gPrO7tZGa2CPg88F53P1TAz5GTRFoX2cQxFVSUlrC1VS0YESlesQWYMKZyJbAKeA64093XmNk1ZvbekO1moN7MmoHPAVeFY9cAdwJrgd8BV7h7J4CZ/RR4GDjBzDab2WWhrP8ExgH3mNmTZnZjXJ8tk9Sd/BVlJZgZU+oq2a4uMhEpYmVxFu7uK4GVPdK+nLbdBlyc5dhrgWszpC/Lkn/egCo7QIlkJ2UlRmmJATC1tpqtCjAiUsRG3SD/UEk9LjllSl0V29RFJiJFTAGmQBLJTirLS7vfT62rYltLG4M810BEZNhQgCmQREePFkxtFYlkF/sOdQxhrUREho4CTIG0dx4dYLqnKqubTESKlAJMgUQtmCNdZMfU6WZLESluCjAFEo3BHPk6p9VVA7Bln262FJHipABTID1nkU0eV0lFaQmb9g76PZ8iIsOCAkyBJJJdVKQFmJISY8aEajbtUYARkeKkAFMgiWTnUWMwADMn1rBpj7rIRKQ4KcAUSM9pygAzJ1bzilowIlKkFGAKpOcYDMDMCTW0HO6g5bDuhRGR4qMAUyDtya7XdJHNmlgDoHEYESlKCjAF0nOaMkRjMACbNZNMRIqQAkyBZOwi627BaKBfRIqPAkyBJDJ0kdVVl1NbVcbLew4OUa1ERIaOAkwBJDu76Ozy17RgAOZOGsPGXeoiE5HiowBTAKnHJVdkCDDHTR7LSzsPDHaVRESGnAJMAaQCTKYWzHENY9na0saBRHKwqyUiMqQUYAogkewEOOqBYynHNYwFYL1aMSJSZGINMGa2yMzWmVmzmV2VYX+lmd0R9j9qZnPS9l0d0teZ2YVp6beY2Q4ze7ZHWRPN7B4zezH8nBDnZ0uX6Mjegpk3eQyAuslEpOjEFmDMrBS4AbgIWAAsM7MFPbJdBux193nA9cB14dgFwFLgZGAR8N1QHsCtIa2nq4B73X0+cG94PyjaO1MB5rUtmFkTx1BaYry0QzPJRKS4xNmCWQg0u/t6d28HlgOLe+RZDNwWtu8CLjAzC+nL3T3h7huA5lAe7v5HYE+G86WXdRvwvgJ+ll711oKpKCthdn2NWjAiUnTiDDDTgU1p7zeHtIx53D0JtAD1OR7b0xR33xq2twFTMmUys8vNrMnMmnbu3JnL5+jTkTGYzF/ncQ2aSSYixWdUDvK7uwOeZd9N7t7o7o0NDQ0FOd+RWWSv7SIDmDd5LBt2HaQ95BMRKQZxBpgtwMy09zNCWsY8ZlYG1AG7czy2p+1mNjWUNRXYkXfN+ynVgsl0HwzASVNr6eh0tWJEpKjEGWAeA+ab2VwzqyAatF/RI88K4NKwvQS4L7Q+VgBLwyyzucB8YHUf50sv61Lg7gJ8hpz0NgYDsGDqOADWvto6WFUSERlysQWYMKZyJbAKeA64093XmNk1ZvbekO1moN7MmoHPEWZ+ufsa4E5gLfA74Ap37wQws58CDwMnmNlmM7sslPVV4O1m9iLwtvB+UPR2oyXA3EljqSovYe1WBRgRKR5lcRbu7iuBlT3Svpy23QZcnOXYa4FrM6Qvy5J/N3DBQOqbr95utAQoLTFOmDKO5xRgRKSIjMpB/sHW3kcLBmDBtFrWbm0l6gEUERn9FGAKoK8uMoAFU2vZd6iDrS1tg1UtEZEhpQBTAH1NU4ZoJhnAGg30i0iRUIApgERHJ2ZQXmpZ8yyYVkuJwdOb9w1exUREhpACTAGkHpccrXKTWU1FGSceU8sTr+wbvIqJiAyhPgOMmR1vZvemVi82s1PN7IvxV23kSCS7qCjtO1afPms8T23aR1eXBvpFZPTLpQXzA+BqoAPA3Z8mumlSgkSyM+sU5XSnz5rA/kRSd/SLSFHIJcDUuHvPu+j1eMY0iY6uXmeQpZw+azyAuslEpCjkEmB2mdlxhMUjzWwJsLX3Q4pLagymL3Prx1BXXc4Tm/YOQq1ERIZWLnfyXwHcBJxoZluADcAlsdZqhIkCTN9dZCUlxutnjufxlxVgRGT0y6UF4+7+NqABONHdz83xuKIRjcHk9pUsnDuRF7YfYPeBRMy1EhEZWrlcFX8O4O4H3X1/SLsrviqNPLl2kQGcc1w9AI+sz/RQThGR0SNrF5mZnQicDNSZ2QfSdtUCVXFXbCRJJLsYX12eU97XTa9jTEUpD6/fxbtOnRpzzUREhk5vYzAnAO8GxgPvSUvfD3w8xjqNOImOTirGVeaUt7y0hIVzJ/Lnl3bHXCsRkaGVNcC4+93A3WZ2jrs/PIh1GnHa+9FFBlE32f3rdrK9tY0ptWoMisjolMsssifM7Aqi7rLuq6G7fzS2Wo0wuc4iSznn2EkAPPzSbt53+vS4qiUiMqRy+bP7x8AxwIXAH4AZRN1kEvRnFhlEC1/Wj6nggXU7YqyViMjQyuWqOM/dvwQcdPfbgHcBfxVvtUaW/swig+gJl285oYEHXthJp9YlE5FRKperYkf4uc/MTgHqgMnxVWnk6W8XGcAFJ05h36EOnnhFN12KyOiUS4C5ycwmAF8EVgBrgetirdUI4u79HuQHeNPxkygrMe59Xt1kIjI69XlVdPcfuvted/+jux/r7pOB3+ZSuJktMrN1ZtZsZldl2F9pZneE/Y+a2Zy0fVeH9HVmdmFfZZrZBWb2FzN70sz+ZGbzcqnjQHU/zbIfYzAAtVXlnDVnIvc9pwAjIqNTr1dFMzvHzJaY2eTw/lQz+wnwUF8Fm1kpcANwEbAAWGZmC3pkuwzY6+7zgOsJLaOQbynRzLVFwHfNrLSPMr8HXOLurwd+QtTiil0uj0vO5oKTJrNu+35e3n2w0NUSERlyWQOMmX0duAX4IPAbM/sP4PfAo8D8HMpeCDS7+3p3bweWA4t75FkM3Ba27wIusOixkIuB5e6ecPcNQHMor7cynWiVAYjGiV7NoY4Dlkh2AlDRzy4ygEWnHAPAr5/W4tQiMvr0dh/Mu4DT3b0tjMFsAk5x9405lj09HJOymdfOPuvO4+5JM2sB6kP6Iz2OTd0wkq3MjwErzeww0AqcnalSZnY5cDnArFmzcvwo2SU6Ui2Y/geYGRNqOH3WeH799FaueOug9OiJiAya3q6Kbe7eBuDue4EX+xFchsJngXe6+wzgv4BvZsrk7je5e6O7NzY0NAz4pEe6yPJbYPrdp07jua2tesqliIw6vV0VjzWzFakXMLfH+75sAWamvZ8R0jLmMbMyoq6t3b0cmzHdzBqA09z90ZB+B/CGHOo4YKkusnzGYADe9bqpmMFv1E0mIqNMb11kPcdL/k8/y34MmG9mc4kCw1Lgb3rkWQFcCjwMLAHuc3cPAewnZvZNYBrRmM9qwLKUuZdo1efj3f0F4O3Ac/2sb17a85xFlnJMXRVnzZ7I3U9u4R/Pn0c0BCUiMvL1ttjlHwZScBhTuRJYBZQCt7j7GjO7Bmhy9xXAzcCPzawZ2EMUMAj57iS65yYJXOHunQCZygzpHwd+bmZdRAFnUNZKG2gXGcAHz5zOv/z8Gf7yyl7OnD2xUFUTERlSuSx2mTd3Xwms7JH25bTtNuDiLMdeC1ybS5kh/ZfALwdY5X4byDTllHefOo1rfrWWOx7bpAAjIqOGHn08QImO1BhM/l/lmMoy3nPaNH711Fb2t3X0fYCIyAigADNAhegiA/jrs2ZyuKNT98SIyKjRZxeZmf2K6CbGdC1AE/D91FTmYlWILjKA02eO54Qp4/jRwy+z9KyZGuwXkREvlz+71wMHgB+EVyvR82COD++LWvc05TxnkaWYGR954xye29rKw+v1OGURGflyuSq+wd3/xt1/FV5/C5zl7lcAZ8Rcv2FvIHfy9/S+06dTP6aCW/60YcBliYgMtVyuimPNrHtNlbA9Nrxtj6VWI0h7Z2G6yACqyku55OzZ3Pv8Dtbrzn4RGeFyCTD/BPzJzO43sweAB4F/NrMxHFmosmilWjD5LHaZyd+dPZvykhJ+qFaMiIxwfQ7yu/tKM5sPnBiS1qUN7P/fuCo2UiSSnZSXGqUlhRmUbxhXycWNM7izaROfPO84ZkyoKUi5IiKDLdc/u88kejbLacBfm9nfx1elkSWfxyX35Yq3zsMwbrj/pYKWKyIymPoMMGb2Y+AbwLnAWeHVGHO9RoxEsrMgA/zppo2v5kNnzeRnTZvYtOdQQcsWERksuSwV0wgscPee98II0RhMocZf0n3yrcdxx2Ob+Pa9L/L1i08rePkiInHL5cr4LHBM3BUZqaIussIHmKl11fzdObO56y+bWfNqS8HLFxGJWy5XxknAWjNb1c/nwRSFqIussGMwKZ86fz7jq8u55ldrUQNSREaaXLrIvhJ3JUayRLJrwHfxZ1NXU87n3n48X7p7DavWbGfRKWpIisjIkcs05QE9F2a0a4+piyxl2cJZ/Ojhl7l25VrecnwD1RXxtJZERAot65XRzP4Ufu43s9a0134zax28Kg5vcUxTTldWWsK/v+8UNu05zPX//UJs5xERKbSsAcbdzw0/x7l7bdprnLvXDl4Vh7c4pin3dPax9SxbOIsfPriepzfvi/VcIiKFktOV0cxKzWyamc1KveKu2EiR6IhvDCbdVRedyKSxlXz+rqdpD48IEBEZznK50fIfge3APcBvwuvXMddrxEgku6gojT/A1FWX8x/vO4Xnt+3nm/eoq0xEhr9croyfBk5w95Pd/XXhdWouhZvZIjNbZ2bNZnZVhv2VZnZH2P+omc1J23d1SF9nZhf2VaZFrjWzF8zsOTP7VC51HKg4pyn39I6Tj2HZwpl8/48v8VDzrkE5p4hIvnIJMJuInmDZL2ZWCtwAXAQsAJaZ2YIe2S4D9rr7POB64Lpw7AJgKdH6Z4uA74Zuut7K/DAwEzjR3U8Clve3zvmIc5pyJl969wKOnTSGz97xJHsOFv3TEkRkGMv1iZYPhBbF51KvHI5bCDS7+3p3bye64C/ukWcxR5b8vwu4wKJnBS8Glrt7wt03AM2hvN7K/AfgGnfvAnD3HTnUccASHfFOU+6ppqKM7yw7g32HOvj08ifo7NINmCIyPOVyZXyFaPylAhiX9urLdKLWT8rmkJYxj7sniVpK9b0c21uZxwEfMrMmM/tteMTAa5jZ5SFP086dO3P4GL1r74x3mnImC6bV8r8Wn8yDL+7ia797flDPLSKSq15vtAxdUse7+yWDVJ+BqATa3L3RzD4A3AK8qWcmd78JuAmgsbFxQH/+Jzu76OzyQW3BpCxbOIu1r7by/T+u56Sptbzv9J6xW0RkaPV6ZXT3TmC2mVXkUfYWojGRlBkhLWMeMysD6oDdvRzbW5mbgV+E7V8COU1EGIhEmC48mGMw6b78ngUsnDuRf/n50zRt3DMkdRARySbXMZiHzOxL/RyDeQyYb2ZzQ4BaCvRcJHMFcGnYXgLcFx4LsAJYGmaZzQXmA6v7KPP/AW8N228BYp/L2x1gBrmLLKW8tITvXXIG08ZXc9ltTbywff+Q1ENEJJNcAsxLRPe9lNCPMZgwpnIlsAp4DrjT3deY2TVm9t6Q7Wag3syagc8BV4Vj1wB3AmuB3wFXuHtntjJDWV8FPmhmzwD/H/CxHD7bgCSSnQBD0kWWUj+2kh99dCEVZSVcestqtrYcHrK6iIiks2JeBr6xsdGbmpryPn7jroOc940H+OZfn8YHzphRwJr135pXW/jQ9x9h8rhKfnr52UyprRrS+ojI6GVmj7t7n082zuVO/gYz+7qZrTSz+1KvwlRzZBvqLrJ0J0+r49aPnMX21jaW3fQI21vbhrpKIlLkcunbuR14HpgL/C9gI9FYSNEbDl1k6RrnTOS2jy5ke2sbS296hG0tCjIiMnRyuTLWu/vNQIe7/8HdPwqcH3O9RoShnkWWSeOcifzosoXs3J/gg9/7M807NPAvIkMjlytjR/i51czeZWanAxNjrNOI0T6MusjSnTl7Ij/9+Nkkkp188HsPawqziAyJXALMf5hZHfBPwD8DPwQ+G2utRojh1kWW7nUz6vjFP7yRiWMquOSHj7Lyma1DXSURKTJ9Xhnd/dfu3uLuz7r7W939THfveT9LUUp0DL8usnSz6mu46xPnsGBaLZ+8/S98fdXzWrtMRAZNLrPIjjeze83s2fD+VDP7YvxVG/6G0yyybOrHVrL88rP5UONMbrj/JS677TFaDnf0faCIyADl8qf3D4CrCWMx7v400R30RS/VRVYxDLvI0lWWlfLVD76Oa99/Cg817+I93/kTT7yyd6irJSKjXC5Xxhp3X90jLRlHZUaaIy2Y4R1gAMyMS/5qNssvP4fOLufiGx/mhvub1WUmIrHJ5cq4y8yOAxzAzJYAGjEmbQxmBASYlDNnT2Dlp9/EolOO4eur1vE3P3iEzXsPDXW1RGQUyuXKeAXwfeBEM9sCfAb4RJyVGimOzCIbvmMwmdRVl/OdZafzjYtP49ktLbzj+j9y60Mb1JoRkYLKZRbZend/G9BA9Djic4H3x16zEaA92YUZlJfaUFel38yMJWfOYNVn38xZcybylV+t5eIb/8yLWpFZRAok574ddz/o7qmrTy7L9Y96iWT0uOToKc8j04wJNdz6kbO4/kOnsWHXQd757Qf53yufo7VNM81EZGDyHTwYuVfUAooCzMjqHsvEzHj/6TO453Nv4f2nT+cHD67n/G88wJ2PbaJL3WYikqd8A4yuOkRjMCNpgL8vk8ZW8rUlp3H3FW9kdv0YPv/zp1l8w0M8+OJOivmxDiKSn6xXRzPbb2atGV77gWmDWMdhK9HRNWzv4h+IU2eM565PnMO3lr6ePQfb+bubV7P0pke0ppmI9EtZth3u3udTK4tdItlFRenoCzAQdZstfv10Fp1yDMtXb+I79zWz5MaHOe+EBj51wXzOmDVhqKsoIsPc6Lw6DpKoi2zkj8H0prKslEvfMIcHP/9WrrroRJ7ctI8PfPfP/PX3H+b+53eo60xEslKAGYBEcnR2kWVSXVHKJ95yHH/6l/P54rtOYtOeQ3zk1se46FsP8ssnNtPR2TXUVRSRYSbWq6OZLTKzdWbWbGZXZdhfaWZ3hP2PmtmctH1Xh/R1ZnZhP8r8tpkdiO1DpUlNUy4mYyvL+NibjuUP//OtfOPi0+jscj57x1O88av3cf09L+hRzSLSLbaro5mVAjcAFwELgGVmtqBHtsuAve4+D7geuC4cu4BoQc2TgUXAd82stK8yzawRGLTBgdEyTTkfFWUl0Y2an3kzt3y4kZOm1vKte1/kDV+9j0/e/jgPv7Rb3WciRS7rIH8BLASa3X09gJktBxYDa9PyLAa+ErbvAv7TorsWFwPL3T0BbDCz5lAe2coMwefrwN8wSCsNJDo6qRxXORinGrZKSozzT5zC+SdO4eXdB7n90Ve4s2kTK5/ZxrGTxvDBM2fw/tOnM2189VBXVUQGWZz9O9OBTWnvN4e0jHncPQm0APW9HNtbmVcCK9y914U4zexyM2sys6adO3f26wP11J7sorK8OFswmcyuH8O/vvMkHrn6Ar5x8WlMGlfJ11et443X3cclP3yEnz++mUPtWohbpFjE2YIZNGY2DbgYOK+vvO5+E3ATQGNj44D6cIpxDCYXVeWlLDlzBkvOnMEruw/xiyc284u/bOGffvYUX7r7Wd520hTe+bqpnHdCA1UK0CKjVpwBZgswM+39jJCWKc9mMysD6oDdfRybKf10YB7QHNYFqzGz5jC2E5tEsnPYP2xsqM2qr+EzbzueT18wn8c27uWXT2zmd89uY8VTr1JTUcr5J07mXa+bynknTKa6QsFGZDSJM8A8Bsw3s7lEQWAp0fhIuhXApcDDwBLgPnd3M1sB/MTMvkm0asB8YDXRGmivKdPd1wDHpAo1swNxBxcId/IrwOTEzFg4dyIL507k3xefwiPr97Dy2a2senYbv356K9XlpZx3QgPnnziZ806YTEORj22JjAaxBRh3T5rZlcAqoBS4xd3XmNk1QJO7rwBuBn4cBvH3EB7FHPLdSTQhIAlc4e6dAJnKjOsz9KWYZ5ENRFlpCefOn8S58ydxzXtPZvXGPax8Ziv3rN3Ob5/dhlm0XM0FJ07m/BMnc/K02hG9YrVIsbJinkra2NjoTU1NeR3b1eUc+68r+fQF8/ns248vcM2Kk7uzdmsr9z23g3uf38FTm/fhDpPHVXLuvEm8Yd4k3jivnql1mpEmMpTM7HF3b+wr36gY5B8K7eHO9WK5k38wmBknT6vj5Gl1/OMF89l1IMED63Zy/7odPPDCTn7xRDQMd2zDmCjgHDeJc46tp66mfIhrLiKZKMDkKZEMAUZdZLGZNLayezZaV5fz/Lb9PNS8i4de2sXPmjbzo4dfpsRgwbRazpozkbPmTKRx9gQm11YNddVFBAWYvCWSnQAa5B8kJSXGgmm1LJhWy8fffCztyS6e3LSPPzXvYvWG3fx09Sv810MbAZhdX0Pj7ImcNWcCjXMmclzDGI3hiAwBBZg8JTpSLRgFmKFQUVbSPSsNopte17zaQtPGvTS9vIcH1u3g53/ZDEBddTmnzqjj1Bl1nDZjPKfNHM8UtXJEYqcAk6dUF5nugxkeKspKOH3WBE6fNYGPcyzuzoZdB3ls4x6e3NTCU5v2ceMf1tMZHgF9TG1VFHBmjufUGdG4z8QxFUP8KURGFwWYPB3pItMYzHBkZhzbMJZjG8byobOitMPtnazd2sJTm1p4avM+nt7cwu/Xbu8+ZkptJSdNreWkqbUsCD/nThpDaYm610TyoQCTp+5Bfs0iGzGqK0o5c/ZEzpw9sTut5VAHz2xp4bmtrTy3tZW1W1v504u7SIaWTlV5CSdMGRcFnWm1nHhMLfMmj1VrRyQHCjB50hjM6FBXU95902dKItlJ844DPLd1f3fgWbVmG8sfO7LOav2YCo6bPJb5k8cyb/JY5k8ex7zJY5lSW6kJBSKBAkyeuu+DURfZqFNZVtp9P06Ku7OttY112/bTvOMAzTsO8OKOA/zqqVdpbTuyQvS4yjKOC0Fn7qQxzJ00hjn1Y5gzqYaaCv13k+Ki3/g8JTo0TbmYmBlT66qZWlfNeSdM7k53d3YeSHQHneYdB3hx+wH+8MJO7np881FlTKmtZE59CDoh8MydNIbZ9TVaVVpGJQWYPKXGYKo0BlPUzIzJ46qYPK6KNxw36ah9+9s6eHn3ITbuPsjGXQfZsCvavmftdnYfbE8rA6aMq2LGhGpmTqyJfk6o6X4/ta6KslL9nsnIowCTJ93JL30ZV1XOKdPrOGV63Wv2tbZ1sHHXQTbuPsTGXQd5Zc8hNu89xOoNe7j7ycN0pS0RWFpiHFNbxcyJ1cyYUPOa4DOltkrT5WVYUoDJk+7kl4GorSrn1BnjOXXG+Nfs6+jsYltLG5v2HGLz3sNs2ht+7jnEgy/uZHtr4qj8ZtGyOtPqqjimrip05UXb08ZXc0xttF2uVpAMMgWYPKVmkekvRym08tISZk6sYebEmoz7E8lOtuw9zOa9h9nacpitLW1s3dfG1tY21u88yJ+bd7M/cfSjqTMFoYZxlTSMq2TyuMqom6+2kok1FZTovh8pEAWYPKmLTIZKZVlp902k2exv62BbSxuvtrSxreUwr+5rC+8PZw1CEHXHTRpbEcaVKplcW0nD2EoaasP7EJQaxlXqd1/6pACTp1QXmVowMhyNqypnXFU586eMy5rncHsnO/cn2LG/jR37E0e2WxPs2J/g1ZY2ntrcwu6DCTI9Nmp8TTmTx1VSP6aS+rEV1I+poH5sJRPHHL09aWwFtVXlahkVIQWYPCWSXZSXmpYRkRGruqKUWfU1zKrP3BWXkuzsYvfBdna0Jth54EgASgWj3QfbWfNqK7sOJNjf9tpWEUQtowk1UbCZGIJP/ZjU9tEBaUJNBbVVZZo5NwoowOSpXY9LliJRVlrClNqqsAL1a2fEpWtPdrH3UDu7DiTYc7Cd3Qfa2X2wnT0HE93buw8keGbzPnYfbM8akABqq8oYX1PBhJpyxtdUML6mnAnh5/jqciaMqYjSq0P6mHLGVZZpJYVhRAEmT4lkp2aQifRQUZYejPqWSHay92AHu0MA2nOwnX2H2tl7qIN9h9rZd7iDvYc62HuonQ27DrL3UO9BqbTEGF9dHgWhEHxqq8upqy6ntqqM2vC+tiqkVZdF2zXljK0oUzdegcUaYMxsEfAtoBT4obt/tcf+SuBHwJnAbuBD7r4x7LsauAzoBD7l7qt6K9PMbgcagQ5gNfA/3L0jrs+W6OhSgBEZoMqyUo6pK+WYutyfz5Ps7KIlBJ6Ww+3sPRgFoCitnX2HOtgXgtLWljZe2LGflkMd7E8kM44lpZhFS/3U1UQB6DVBKBWcqssYV1nO2KoyxlUd2R5bWaYx2R5iCzBmVgrcALwd2Aw8ZmYr3H1tWrbLgL3uPs/MlgLXAR8yswXAUuBkYBrw32Z2fDgmW5m3A38b8vwE+Bjwvbg+XyLZRaWW9xAZdGWlJdEYztjKfh3X1eUcaE/ScqiD1rYOWg8naTmc2g6vtiSthzu60zfsOti9fai9s89zVJaVREGnqpyxlVHQORKIUtvRvnEhfWzl0e/HVJaNmnuW4mzBLASa3X09gJktBxYD6QFmMfCVsH0X8J8WdaAuBpa7ewLYYGbNoTyylenuK1OFmtlqYEZcHwyipn3FKPklECkGJSXW3TLJR0dnV3cQOtCWZH9b1CpKbR9IJNmfSLI/7D+QiNI37TkUtqO0zq5emlFBRWkJYypLqamIglRNZSljK8sYU3FkO9p3JM+YyvR96XnKqCovGZKxqTgDzHRgU9r7zcBfZcvj7kkzawHqQ/ojPY6dHrZ7LdPMyoG/Az49wPr3KmrBKMCIFIvyPFtO6dydto6uHsEpyYFEB/vD9qH2JAcSneFnkkOJTg6G7R2tiSitPcnBRGf3qu59KTEYU3F0EPq39yw46tlIcRiNg/zfBf7o7g9m2mlmlwOXA8yaNSvvk2gMRkT6y8yoriiluqKUyX1n71N7sutIIGrv7A5IR4LQa4PVgfYkhxLJQZkFG2eA2QLMTHs/I6RlyrPZzMqI5kDu7uPYrGWa2b8BDcD/yFYpd78JuAmgsbGx77ZqFolkp57vISJDqqKshIqyaLr2cBTnn+CPAfPNbK6ZVRAN2q/okWcFcGnYXgLc5+4e0peaWaWZzQXmE80My1qmmX0MuBBY5u65tRsHoL1TLRgRkd7E9id4GFO5ElhFNKX4FndfY2bXAE3uvgK4GfhxGMTfQxQwCPnuJJoQkASucPdOgExlhlPeCLwMPBwGs37h7tfE9fkSHRqDERHpTax9PGFm18oeaV9O224DLs5y7LXAtbmUGdIHtb8qoTv5RUR6pT/B86Q7+UVEeqcrZJ6iFoy+PhGRbHSFzFOio0vLQoiI9EJXyDy4e+gi0xiMiEg2CjB5SHY5XY66yEREeqErZB66H5esacoiIlnpCpmH9lSAUReZiEhWCjB5SCSjZbvVRSYikp2ukHlIdKiLTESkL7pC5iGhLjIRkT4pwOQh1UWmB46JiGSnK2QeNItMRKRvukLmoXsMRl1kIiJZKcDkQbPIRET6pitkHtrVRSYi0iddIfOgWWQiIn1TgMmDushERPqmK2QejrRg9PWJiGSjK2QejtzJry4yEZFsFGDyoBstRUT6FusV0swWmdk6M2s2s6sy7K80szvC/kfNbE7avqtD+jozu7CvMs1sbiijOZRZEdfnSiS7MIPyUovrFCIiI15sAcbMSoEbgIuABcAyM1vQI9tlwF53nwdcD1wXjl0ALAVOBhYB3zWz0j7KvA64PpS1N5Qdi0Syi8qyEswUYEREsomzBbMQaHb39e7eDiwHFvfIsxi4LWzfBVxg0VV7MbDc3RPuvgFoDuVlLDMcc34og1Dm++L6YIkOPS5ZRKQvZTGWPR3YlPZ+M/BX2fK4e9LMWoD6kP5Ij2Onh+1MZdYD+9w9mSH/UczscuBygFmzZvXvEwUnTa3lcEdnXseKiBSLohuldveb3L3R3RsbGhryKmPpwll8bclpBa6ZiMjoEmeA2QLMTHs/I6RlzGNmZUAdsLuXY7Ol7wbGhzKynUtERAZRnAHmMWB+mN1VQTRov6JHnhXApWF7CXCfu3tIXxpmmc0F5gOrs5UZjrk/lEEo8+4YP5uIiPQhtjGYMKZyJbAKKAVucfc1ZnYN0OTuK4CbgR+bWTOwhyhgEPLdCawFksAV7t4JkKnMcMp/AZab2X8AT4SyRURkiFj0x39xamxs9KampqGuhojIiGJmj7t7Y1/5im6QX0REBocCjIiIxEIBRkREYqEAIyIisSjqQX4z2wm8nOfhk4BdBaxOoahe/aN69Y/q1T/DtV4wsLrNdvc+71Qv6gAzEGbWlMssisGmevWP6tU/qlf/DNd6weDUTV1kIiISCwUYERGJhQJM/m4a6gpkoXr1j+rVP6pX/wzXesEg1E1jMCIiEgu1YEREJBYKMCIiEg9316ufL2ARsI7oUc5XxVD+TKLHD6wF1gCfDulfIXrOzZPh9c60Y64O9VkHXNhXXYG5wKMh/Q6gIse6bQSeCedvCmkTgXuAF8PPCSHdgG+HczwNnJFWzqUh/4vApWnpZ4bym8OxlkOdTkj7Tp4EWoHPDNX3BdwC7ACeTUuL/TvKdo4+6vV14Plw7l8C40P6HOBw2nd3Y77n7+0z9lKv2P/tgMrwvjnsn5NDve5Iq9NG4MnB/L7Ifm0Y8t+vjP8XCn1xHO0voscEvAQcC1QATwELCnyOqalfBGAc8AKwIPyn++cM+ReEelSG/0wvhXpmrStwJ7A0bN8I/EOOddsITOqR9jXCf2jgKuC6sP1O4Lfhl/xs4NG0X9T14eeEsJ36D7E65LVw7EV5/PtsA2YP1fcFvBk4g6MvTLF/R9nO0Ue93gGUhe3r0uo1Jz1fj3L6df5sn7GPesX+bwd8khAIiB4Vckdf9eqx//8AXx7M74vs14Yh//3K+Nn7e/Er9hdwDrAq7f3VwNUxn/Nu4O29/Kc7qg5Ez8s5J1tdwy/OLo5cWI7K10ddNvLaALMOmBq2pwLrwvb3gWU98wHLgO+npX8/pE0Fnk9LPypfjvV7B/BQ2B6y74seF5zB+I6ynaO3evXY937g9t7y5XP+bJ+xj+8r9n+71LFhuyzks97qlZZuwCZg/lB8X2n7UteGYfH71fOlMZj+m070i5WyOaTFwszmAKcTNeEBrjSzp83sFjOb0EedsqXXA/vcPdkjPRcO/N7MHjezy0PaFHffGra3AVPyrNf0sN0zvT+WAj9Nez/U31fKYHxH2c6Rq48S/cWaMtfMnjCzP5jZm9Lq29/z5/t/Ju5/u+5jwv6WkD8XbwK2u/uLaWmD+n31uDYMy98vBZhhzMzGAj8HPuPurcD3gOOA1wNbiZrog+1cdz8DuAi4wszenL7Toz9vfAjqRXiM9nuBn4Wk4fB9vcZgfEf9PYeZfYHo6bG3h6StwCx3Px34HPATM6uN6/wZDMt/uzTLOPoPmUH9vjJcG/IuKx+5nkMBpv+2EA20pcwIaQVlZuVEv0C3u/svANx9u7t3unsX8ANgYR91ypa+GxhvZmU90vvk7lvCzx1Eg8ILge1mNjXUeyrRwGg+9doStnum5+oi4C/uvj3Ucci/rzSD8R1lO0evzOzDwLuBS8KFA3dPuPvusP040fjG8Xmev9//Zwbp3677mLC/LuTvVcj7AaIB/1R9B+37ynRtyKOsQfn9UoDpv8eA+WY2N/zFvBRYUcgTmJkBNwPPufs309KnpmV7P/Bs2F4BLDWzSjObC8wnGqjLWNdwEbkfWBKOv5SoL7eveo0xs3GpbaLxjmfD+S/NUNYK4O8tcjbQEprYq4B3mNmE0PXxDqJ+8a1Aq5mdHb6Dv8+lXmmO+qtyqL+vHgbjO8p2jqzMbBHweeC97n4oLb3BzErD9rFE39H6PM+f7TP2Vq/B+LdLr+8S4L5UgO3D24jGKbq7kgbr+8p2bcijrEH5/SroYHSxvIhmZrxA9FfKF2Io/1yi5ufTpE3TBH5MNH3w6fCPPTXtmC+E+qwjbeZVtroSzbZZTTQV8WdAZQ71OpZods5TRFMkvxDS64F7iaYv/jcwMaQbcEM49zNAY1pZHw3nbgY+kpbeSHQxeQn4T3KYphyOG0P012ddWtqQfF9EQW4r0EHUh33ZYHxH2c7RR72aifriU79nqVlVHwz/xk8CfwHek+/5e/uMvdQr9n87oCq8bw77j+2rXiH9VuATPfIOyvdF9mvDkP9+ZXppqRgREYmFushERCQWCjAiIhILBRgREYmFAoyIiMRCAUZERGKhACPST2ZWb2ZPhtc2M9uS9r6ij2Mbzezb/TzfR83sGYuWTXnWzBaH9A+b2bSBfBaROGmassgAmNlXgAPu/o20tDI/svbVQMufAfyBaAXdlrBESIO7bzCzB4gWhGwqxLlECk0tGJECMLNbzexGM3sU+JqZLTSzhy1a/PDPZnZCyHeemf06bH/FooUcHzCz9Wb2qQxFTwb2AwcA3P1ACC5LiG6Iuz20nKrN7EyLFlp83MxW2ZFlPR4ws2+FfM+a2cIM5xEpOAUYkcKZAbzB3T9H9BCvN3m0+OGXgf+d5ZgTgQuJ1tr6N4vWmUr3FLAd2GBm/2Vm7wFw97uAJqL1w15PtFDld4Al7n4m0cOyrk0rpybk+2TYJxK7sr6ziEiOfubunWG7DrjNzOYTLe3RM3Ck/MbdE0DCzHYQLYHevcaVu3eG9cLOAi4ArjezM939Kz3KOQE4BbgnWkKKUqJlTlJ+Gsr7o5nVmtl4d9+X/0cV6ZsCjEjhHEzb/nfgfnd/v0XP7XggyzGJtO1OMvyf9GigdDWw2szuAf6L6IFc6QxY4+7nZDlPz8FWDb5K7NRFJhKPOo4sc/7hfAsxs2lmdkZa0uuBl8P2fqLH5kK08GODmZ0Tjis3s5PTjvtQSD+XaEXdlnzrJJIrtWBE4vE1oi6yLwK/GUA55cA3wnTkNmAn8Imw71bgRjM7TPQo4CXAt82sjuj/9v8lWuEXoM3MngjlfXQA9RHJmaYpi4xyms4sQ0VdZCIiEgu1YEREJBZqwYiISCwUYEREJBYKMCIiEgsFGBERiYUCjIiIxOL/BxWPw2YhM9c1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a94d3",
   "metadata": {},
   "source": [
    "**1. 모델 컴파일  및 훈련(Layer=2, D_MODEL=256)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5afbd238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='accuracy',     # 모니터링 대상\n",
    "    patience=3,             # 개선 없으면 몇 epoch 후에 멈출지\n",
    "    restore_best_weights=True,  # 가장 성능 좋았던 가중치를 복원할지 여부\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "169f63da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3139072     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3666432     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8144)   2093008     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,898,512\n",
      "Trainable params: 8,898,512\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() # TensorFlow에서 메모리 관리와 관련된 문제를 방지하기 위해 사용하는 함수\n",
    "                                 # Keras의 전역 상태(예: 모델, 레이어, 그래프 등)를 초기화해서 메모리를 정리\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수  ( 논문 6->2)\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원  (논문 512 -> 256)\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model_1 = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "409c74ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model_1.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fdcc667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0035 - accuracy: 0.1734\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0037 - accuracy: 0.1734\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0034 - accuracy: 0.1734\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 10s 56ms/step - loss: 0.0035 - accuracy: 0.1734\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 10s 56ms/step - loss: 0.0034 - accuracy: 0.1734\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 10s 56ms/step - loss: 0.0033 - accuracy: 0.1734\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0029 - accuracy: 0.1735\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0032 - accuracy: 0.1735\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0033 - accuracy: 0.1734\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0031 - accuracy: 0.1734\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0029 - accuracy: 0.1735\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0028 - accuracy: 0.1735\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 10s 56ms/step - loss: 0.0030 - accuracy: 0.1735\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 10s 56ms/step - loss: 0.0029 - accuracy: 0.1736\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 10s 56ms/step - loss: 0.0027 - accuracy: 0.1736\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0028 - accuracy: 0.1735\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0026 - accuracy: 0.1736\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0026 - accuracy: 0.1735\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0025 - accuracy: 0.1736\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0028 - accuracy: 0.1735\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0024 - accuracy: 0.1736\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0023 - accuracy: 0.1736\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0027 - accuracy: 0.1735\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0024 - accuracy: 0.1736\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0022 - accuracy: 0.1736\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0022 - accuracy: 0.1736\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0022 - accuracy: 0.1736\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0021 - accuracy: 0.1736\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0021 - accuracy: 0.1736\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0022 - accuracy: 0.1736\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0021 - accuracy: 0.1736\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0020 - accuracy: 0.1736\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0023 - accuracy: 0.1736\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0022 - accuracy: 0.1736\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0021 - accuracy: 0.1736\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0019 - accuracy: 0.1737\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0020 - accuracy: 0.1737\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0018 - accuracy: 0.1736\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0021 - accuracy: 0.1736\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0019 - accuracy: 0.1736\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0020 - accuracy: 0.1736\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0019 - accuracy: 0.1737\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0019 - accuracy: 0.1736\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0020 - accuracy: 0.1736\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0016 - accuracy: 0.1737\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0018 - accuracy: 0.1737\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0017 - accuracy: 0.1737\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0019 - accuracy: 0.1736\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0016 - accuracy: 0.1737\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0016 - accuracy: 0.1737\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "#history_1 = model_1.fit(dataset, epochs=EPOCHS, verbose=1, callbacks = early_stop)\n",
    "history_1 = model_1.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f76af4a",
   "metadata": {},
   "source": [
    "**2. 모델 컴파일  및 훈련 (Layer=6, D_MODEL=256)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "131053b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    5247488     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    6829568     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8144)   2093008     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,170,064\n",
      "Trainable params: 14,170,064\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() # TensorFlow에서 메모리 관리와 관련된 문제를 방지하기 위해 사용하는 함수\n",
    "                                 # Keras의 전역 상태(예: 모델, 레이어, 그래프 등)를 초기화해서 메모리를 정리\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수  ( 논문 6->2)\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원  (논문 512 -> 256)\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model_2 = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d83e1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model_2.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6c01a755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "185/185 [==============================] - 36s 118ms/step - loss: 1.4405 - accuracy: 0.0218\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 22s 121ms/step - loss: 1.1848 - accuracy: 0.0439\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 1.0189 - accuracy: 0.0500\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.9515 - accuracy: 0.0520\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.9136 - accuracy: 0.0544\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.8809 - accuracy: 0.0562\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.8456 - accuracy: 0.0582\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.8079 - accuracy: 0.0603\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.7674 - accuracy: 0.0629\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.7246 - accuracy: 0.0660\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.6805 - accuracy: 0.0696\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 22s 122ms/step - loss: 0.6346 - accuracy: 0.0742\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 26s 139ms/step - loss: 0.5905 - accuracy: 0.0790\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 30s 160ms/step - loss: 0.5456 - accuracy: 0.0847\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 31s 165ms/step - loss: 0.5034 - accuracy: 0.0899\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 31s 167ms/step - loss: 0.4651 - accuracy: 0.0948\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 31s 169ms/step - loss: 0.4313 - accuracy: 0.0995\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 31s 165ms/step - loss: 0.3997 - accuracy: 0.1041\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 23s 123ms/step - loss: 0.3782 - accuracy: 0.1068\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 23s 122ms/step - loss: 0.3579 - accuracy: 0.1096\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 22s 119ms/step - loss: 0.3449 - accuracy: 0.1118\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.3347 - accuracy: 0.1135\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.3208 - accuracy: 0.1157\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.3067 - accuracy: 0.1185\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2962 - accuracy: 0.1207\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2860 - accuracy: 0.1227\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2795 - accuracy: 0.1241\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 22s 119ms/step - loss: 0.2731 - accuracy: 0.1251\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2668 - accuracy: 0.1262\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2624 - accuracy: 0.1270\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2570 - accuracy: 0.1280\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2529 - accuracy: 0.1286\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2487 - accuracy: 0.1292\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2454 - accuracy: 0.1296\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2404 - accuracy: 0.1304\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2383 - accuracy: 0.1307\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2335 - accuracy: 0.1315\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2313 - accuracy: 0.1317\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2273 - accuracy: 0.1323\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2259 - accuracy: 0.1327\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2223 - accuracy: 0.1332\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2205 - accuracy: 0.1332\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2171 - accuracy: 0.1339\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2141 - accuracy: 0.1343\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2127 - accuracy: 0.1345\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2102 - accuracy: 0.1348\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2087 - accuracy: 0.1350\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2059 - accuracy: 0.1355\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2042 - accuracy: 0.1358\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2030 - accuracy: 0.1359\n"
     ]
    }
   ],
   "source": [
    "#EPOCHS = 10\n",
    "history_2 = model_2.fit(dataset, epochs=EPOCHS, verbose=1, callbacks = early_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6a02e4",
   "metadata": {},
   "source": [
    "**3. 모델 컴파일  및 훈련 (Layer=6, D_MODEL=512)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f8a88028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    13637632    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    19947520    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8144)   4177872     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 37,763,024\n",
      "Trainable params: 37,763,024\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() # TensorFlow에서 메모리 관리와 관련된 문제를 방지하기 위해 사용하는 함수\n",
    "                                 # Keras의 전역 상태(예: 모델, 레이어, 그래프 등)를 초기화해서 메모리를 정리\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수  ( 논문 6->2)\n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원  (논문 512 -> 256)\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model_3 = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4ce550e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model_3.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "38294240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "185/185 [==============================] - 56s 228ms/step - loss: 1.3449 - accuracy: 0.0231\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 42s 225ms/step - loss: 1.0721 - accuracy: 0.0492\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.9788 - accuracy: 0.0509\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.9351 - accuracy: 0.0530\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 42s 225ms/step - loss: 0.9032 - accuracy: 0.0549\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.8663 - accuracy: 0.0572\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 42s 227ms/step - loss: 0.8255 - accuracy: 0.0595\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 42s 227ms/step - loss: 0.7795 - accuracy: 0.0623\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 42s 227ms/step - loss: 0.7263 - accuracy: 0.0663\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 42s 227ms/step - loss: 0.6676 - accuracy: 0.0716\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.6080 - accuracy: 0.0778\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.5504 - accuracy: 0.0842\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.4948 - accuracy: 0.0910\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.4459 - accuracy: 0.0975\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 42s 227ms/step - loss: 0.4027 - accuracy: 0.1032\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.3672 - accuracy: 0.1078\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 42s 227ms/step - loss: 0.3382 - accuracy: 0.1115\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 42s 227ms/step - loss: 0.3175 - accuracy: 0.1142\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.2995 - accuracy: 0.1170\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.2865 - accuracy: 0.1184\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.2784 - accuracy: 0.1196\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.2685 - accuracy: 0.1212\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.2567 - accuracy: 0.1229\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.2420 - accuracy: 0.1252\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 42s 227ms/step - loss: 0.2279 - accuracy: 0.1274\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.2170 - accuracy: 0.1292\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.2056 - accuracy: 0.1308\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.1966 - accuracy: 0.1322\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.1867 - accuracy: 0.1338\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 42s 225ms/step - loss: 0.1800 - accuracy: 0.1347\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 42s 225ms/step - loss: 0.1722 - accuracy: 0.1360\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 42s 225ms/step - loss: 0.1652 - accuracy: 0.1372\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.1588 - accuracy: 0.1382\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 42s 225ms/step - loss: 0.1537 - accuracy: 0.1388\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 42s 225ms/step - loss: 0.1477 - accuracy: 0.1400\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.1411 - accuracy: 0.1410\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.1365 - accuracy: 0.1417\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.1313 - accuracy: 0.1429\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 42s 225ms/step - loss: 0.1270 - accuracy: 0.1434\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.1212 - accuracy: 0.1445\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.1176 - accuracy: 0.1452\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.1133 - accuracy: 0.1463\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 42s 225ms/step - loss: 0.1082 - accuracy: 0.1471\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 42s 225ms/step - loss: 0.1043 - accuracy: 0.1478\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 42s 225ms/step - loss: 0.1017 - accuracy: 0.1483\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 42s 225ms/step - loss: 0.1004 - accuracy: 0.1485\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.0949 - accuracy: 0.1497\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.0924 - accuracy: 0.1503\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 42s 225ms/step - loss: 0.0902 - accuracy: 0.1506\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 42s 226ms/step - loss: 0.0867 - accuracy: 0.1513\n"
     ]
    }
   ],
   "source": [
    "#EPOCHS = 10\n",
    "history_3 = model_3.fit(dataset, epochs=EPOCHS, verbose=1, callbacks = early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8e4a6350",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history_3.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "eb60736e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "acc1 = history_1.history['accuracy']\n",
    "loss1 = history_1.history['loss']\n",
    "\n",
    "\n",
    "acc2 = history_2.history['accuracy']\n",
    "loss2 = history_2.history['loss']\n",
    "\n",
    "acc3 = history_3.history['accuracy']\n",
    "loss3 = history_3.history['loss']\n",
    "\n",
    "epochs_range = range(1, len(acc1) + 1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc1, 'b', label='Training Accuracy1')\n",
    "plt.plot(epochs_range, acc2, 'g',label='Training Accuracy2')\n",
    "plt.plot(epochs_range, acc3, 'r',label='Training Accuracy3')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss1, 'b',label='Training Loss1')\n",
    "plt.plot(epochs_range, loss2, 'g',label='Training Loss2')\n",
    "plt.plot(epochs_range, loss3, 'r',label='Training Loss3')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7182cfc0",
   "metadata": {},
   "source": [
    "## 테스트 (inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7053ac",
   "metadata": {},
   "source": [
    "1) 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.\n",
    "2) 입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다.\n",
    "3) 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
    "4) 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
    "5) 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "6) END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8ebf0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "     # expand_dims : shape을 (1, sequence_length)로 만들어 배치처럼 보이게\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    #predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = model_1(inputs=[sentence, output_sequence], training=False)\n",
    "    #predictions = model_2(inputs=[sentence, output_sequence], training=False)\n",
    "    #predictions = model_3(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    \n",
    "    # predictions : (batch_size, sequence_length, vocab_size) -> shape : (1, 1, 8333)\n",
    "    # : : 배치 전체 (1)\n",
    "    # -1:은 가장 마지막 토큰의 예측만 가져오기\n",
    "    # : : 전체 vocab에 대한 확률 (8333)\n",
    "    \n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)    # -> shape : (1,1)\n",
    "    #  tf.argmax는 int64 자료형 (자료형의 기본은 int64)\n",
    "    # output_sequece는 int32 자료형 (대부분 TesorFlow 모델은 int32로 처리)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1b1b4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b02fedd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 어제 뭐 했어?\n",
      "출력 : 잘하고 오세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘하고 오세요 . '"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('어제 뭐 했어?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "eb2e433e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : test는 어땠어?\n",
      "출력 : 많이 힘들지 않길 바랄게요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'많이 힘들지 않길 바랄게요 . '"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"test는 어땠어?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c7cf428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내일 비가 올거 같아?\n",
      "출력 : 마음의 준비를 해야 할지도 모르겠어요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'마음의 준비를 해야 할지도 모르겠어요 . '"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"내일 비가 올거 같아?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6b2c4776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내일 뭐 하고 싶어?\n",
      "출력 : 잊어버리세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잊어버리세요 . '"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"내일 뭐 하고 싶어?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f9e242c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 딥러닝으로 이미지 생성 할 수 있어\n",
      "출력 : 잘  ! \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘  ! '"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"딥러닝으로 이미지 생성 할 수 있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "04b755c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 어깨 운동 추천해줄래?\n",
      "출력 : 받는 사람이 부담스럽지 않는 선일 것 같습니다 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'받는 사람이 부담스럽지 않는 선일 것 같습니다 . '"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"어깨 운동 추천해줄래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1843ea7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : what are you doing?\n",
      "출력 : 다른 사람 말은 한 귀로 흘리세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'다른 사람 말은 한 귀로 흘리세요 . '"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"what are you doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8150c100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 호두 정과 정말 맛있어\n",
      "출력 : 상종하지마세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'상종하지마세요 . '"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"호두 정과 정말 맛있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d5b1da98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 흑임자 두부 만드는 법 알아\n",
      "출력 : 상대방도 미소짓게 해주세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'상대방도 미소짓게 해주세요 . '"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"흑임자 두부 만드는 법 알아\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161d741f",
   "metadata": {},
   "source": [
    "## 회고 \n",
    "\n",
    "Layer와 D_Model을 크게하면, 학습에 시간이 오래 걸리므로, epoch를 크게 줘야 함. \n",
    "\n",
    "질문에 대한 답변이 적절하지는 않지만, 짧은 문장으로 부드럽게 응답한다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
